{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecualizaci칩n de histograma\n",
    "\n",
    "Global y Adaptativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar una imagen en modo monocrom치tico (un canal)\n",
    "img = cv.imread('mib-alien.jpg', cv.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo: Ecualizaci칩n global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nueva figura\n",
    "fig = plt.figure()\n",
    "\n",
    "# Imagen original\n",
    "ax1=plt.subplot(221)\n",
    "ax1.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "ax1.set_title('Original')\n",
    "\n",
    "hist1,bins1 = np.histogram(img.ravel(),256,[0,256])\n",
    "ax3=plt.subplot(223)\n",
    "ax3.plot(hist1)\n",
    "\n",
    "# Imagen ecualizada\n",
    "img_eqzd = cv.equalizeHist(img)\n",
    "ax2=plt.subplot(222)\n",
    "ax2.imshow(img_eqzd, cmap='gray', vmin=0, vmax=255)\n",
    "ax2.set_title('Ecualizada')\n",
    "\n",
    "hist2,bins2 = np.histogram(img_eqzd.ravel(),256,[0,256])\n",
    "ax4=plt.subplot(224)\n",
    "ax4.plot(hist2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo: CLAHE (Ecualizaci칩n adaptativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nueva figura\n",
    "fig = plt.figure()\n",
    "\n",
    "# Imagen original\n",
    "ax1=plt.subplot(221)\n",
    "ax1.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "ax1.set_title('Original')\n",
    "\n",
    "hist1,bins1 = np.histogram(img.ravel(),256,[0,256])\n",
    "ax3=plt.subplot(223)\n",
    "ax3.plot(hist1)\n",
    "\n",
    "# create a CLAHE object (Arguments are optional).\n",
    "clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "img_eqzd = clahe.apply(img)\n",
    "ax2=plt.subplot(222)\n",
    "ax2.imshow(img_eqzd, cmap='gray', vmin=0, vmax=255)\n",
    "ax2.set_title('Ecualizada')\n",
    "\n",
    "hist2,bins2 = np.histogram(img_eqzd.ravel(),256,[0,256])\n",
    "ax4=plt.subplot(224)\n",
    "ax4.plot(hist2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Mostrar las imagenes lado a lado usando cv2.hconcat\n",
    "out1 = cv.hconcat([img, img_eqzd])\n",
    "cv.imshow('Clahe', out1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('vision-robotica')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "0af437b5139b375ee3fab2b21e8a1376590e14b3c752e237587dc080bd8d5be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
