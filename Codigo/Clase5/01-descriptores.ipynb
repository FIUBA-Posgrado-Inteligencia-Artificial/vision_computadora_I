{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Características Locales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Version de OpenCV: 3.4.2\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "%matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "print(f'Version de OpenCV: {cv.__version__}')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos la imagen a procesar\n",
    "img = cv.imread('imagenes/cabildo.jpg')\n",
    "# La transformamos en escala de grises\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. SIFT - características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](./imagenes/sift_docu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad y dimension de los descriptores: (3062, 128)\n",
      "-- 1er keypoint -- \n",
      "Orientacion: 278.9941711425781\n",
      "Octava donde se encontro: 8454655\n",
      "Posicion en la imagen: (2.306810140609741, 457.8912658691406)\n",
      "Descriptores: 3062\n",
      "Keypoints: 3062\n",
      "(2.306810140609741, 457.8912658691406)\n"
     ]
    }
   ],
   "source": [
    "# Instanciamos la clase SIFT\n",
    "sift = cv.xfeatures2d.SIFT_create()\n",
    "kp, descriptors = sift.detectAndCompute(gray, None)\n",
    "# tambien existe la version que se ejecuta sobre GPU\n",
    "# siendo acelerada por CUDA\n",
    "# https://docs.opencv.org/3.4/df/db9/classcv_1_1cuda_1_1Feature2DAsync.html#a56c6c75e25e9616934c25552164a363c\n",
    "\n",
    "# Verificamos cuántas características encontró\n",
    "print(f'Cantidad y dimension de los descriptores: {descriptors.shape}')\n",
    "print(f'-- 1er keypoint -- ')\n",
    "print(f'Orientacion: {kp[0].angle}')\n",
    "print(f'Octava donde se encontro: {kp[0].octave}')\n",
    "print(f'Posicion en la imagen: {kp[0].pt}')\n",
    "print(f'Descriptores: {len(descriptors)}')\n",
    "print(f'Keypoints: {len(kp)}')\n",
    "\n",
    "dir(kp[0])[-10:]\n",
    "print(descriptors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue de opencv sobre el manejo de la octava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/opencv/opencv/issues/4554"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dibujamos las características encontradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "detalle = False\n",
    "if detalle:\n",
    "    # Dibujamos las características encontradas con más detalle\n",
    "    img=cv.drawKeypoints(gray, kp, img, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "else:\n",
    "    # Dibujamos las características encontradas sin mucho detalle\n",
    "    img=cv.drawKeypoints(gray, kp, img)\n",
    "    \n",
    "cv.imshow('detecciones', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. SURF - características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el umbral para el Hessiano\n",
    "hess_thresh = 1500\n",
    "\n",
    "# Calculamos las características con ese umbral\n",
    "surf = cv.xfeatures2d.SURF_create(hess_thresh)\n",
    "kp, des = surf.detectAndCompute(gray, None)\n",
    "\n",
    "# Verificamos cuántas características se encontraron\n",
    "print(len(kp))\n",
    "\n",
    "# Graficamos...\n",
    "Detalle = True\n",
    "if Detalle:\n",
    "    # Dibujamos las características encontradas con más detalle\n",
    "    img2=cv.drawKeypoints(gray, kp, img, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "else:\n",
    "    # Dibujamos las características encontradas sin mucho detalle\n",
    "    img2=cv.drawKeypoints(gray,kp,img)\n",
    "\n",
    "cv.imshow('SURF', img2)\n",
    "#plt.imshow(img2),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. FAST - características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos el objeto FAST con valores por defecto\n",
    "fast = cv.FastFeatureDetector_create()\n",
    "\n",
    "# Encontramos y dibujamos los puntos clave (keypoints)\n",
    "kp = fast.detect(gray, None)\n",
    "\n",
    "# Devolvemos los valores por defecto\n",
    "print( \"Umbral: {}\".format(fast.getThreshold()) )\n",
    "print( \"nonmaxSuppression:{}\".format(fast.getNonmaxSuppression()) )\n",
    "print( \"Vecindario: {}\".format(fast.getType()) )\n",
    "print( \"Keypoints totales con nonmaxSuppression: {}\".format(len(kp)) )\n",
    "\n",
    "# Graficamos\n",
    "img2 = cv.drawKeypoints(gray, kp, None, color=(255,0,0))\n",
    "cv.imshow('FAST - NMS TRUE',img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetimos suprimiendo la no-supresión de máximos (nonmaxSuppression)\n",
    "img = cv.imread('imagenes/cabildo.jpg', 0)\n",
    "fast.setNonmaxSuppression(0)\n",
    "kp = fast.detect(img, None)\n",
    "print( \"Keypoints totales sin nonmaxSuppression: {}\".format(len(kp)) )\n",
    "\n",
    "# Graficamos\n",
    "img3 = cv.drawKeypoints(img, kp, None, color=(255,0,0))\n",
    "cv.imshow('FAST - NMS FALSE', img3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. ORB - características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](./imagenes/orb_docu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv.imread('imagenes/cabildo.jpg', 0)\n",
    "\n",
    "# Inicializamos el detector ORB\n",
    "orb = cv.ORB_create()\n",
    "\n",
    "# Encontramos los puntos clave (keypoints) - Es una versión de FAST\n",
    "kp = orb.detect(gray, None)\n",
    "\n",
    "# Calculamos los descriptores - Es una versión de BRIEF\n",
    "kp, des = orb.compute(gray, kp)\n",
    "# Verificamos cuántas características se encontraron\n",
    "print(len(kp))\n",
    "\n",
    "# Graficamos...\n",
    "Detalle = True\n",
    "if Detalle:\n",
    "    # Dibujamos las características encontradas con más detalle\n",
    "    img2=cv.drawKeypoints(gray,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "else:\n",
    "    # Dibujamos las características encontradas sin mucho detalle\n",
    "    img2=cv.drawKeypoints(gray,kp,img)\n",
    "    \n",
    "cv.imshow('ORB',img2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('vision-robotica')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "0af437b5139b375ee3fab2b21e8a1376590e14b3c752e237587dc080bd8d5be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
